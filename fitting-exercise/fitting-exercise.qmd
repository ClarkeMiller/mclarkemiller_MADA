---
title: "New_Fitting_Exercise"
author: "Clarke Miller"
editor: visual
---

```{r}
#The thing that kept tripping me up here was my own lack of R coding ability.  So I went through this exercise again and worked it out using the solutions provided by Dr. Handel.  The result is that I learned a bit about how to code this stuff.

#I went ahead took a peek at the solutions that Dr. Handel posted.  Katie pointed out that since I had already blown the assignment and since I couldn't figure it out myself that I should probably stop being stubborn (her exact phrase was "being a bone headed stubborn dumb-***"... Love you, Katie!) and peek.  

#Call a bunch of libraries.
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(tidymodels))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(broom)) 
suppressPackageStartupMessages(library(here))
suppressPackageStartupMessages(library(readxl))
suppressPackageStartupMessages(library(readr)) 
suppressPackageStartupMessages(library(dplyr)) 
suppressPackageStartupMessages(library(tidyr)) 
suppressPackageStartupMessages(library(skimr))
suppressPackageStartupMessages(library(gt))
suppressPackageStartupMessages(library(dslabs))
suppressPackageStartupMessages(library(plotly))
suppressPackageStartupMessages(library(gapminder))
suppressPackageStartupMessages(library(parsnip))
suppressPackageStartupMessages(library(tune))
suppressPackageStartupMessages(library(recipes))
suppressPackageStartupMessages(library(workflows))
suppressPackageStartupMessages(library(yardstick))
suppressPackageStartupMessages(library(rsample))

```

```{r}
#Data processing.

#Load excel data file
data_location <- here::here("Mavoglurant_A2121_nmpk.csv")
Mav_data <- read.csv(data_location)

#Save a rds version
save_data_location <- here::here("mav_data.rds")
saveRDS(Mav_data, file = save_data_location)

```

```{r}

library(ggplot2)

#Initial Data Explore.  
summary(Mav_data)
skimr::skim(Mav_data)

plot_DV_vs_time <- ggplot(Mav_data, aes(x=TIME, y=DV)) + geom_point() + theme_classic() + labs(title = "DV vs. Time", x="DV", y="Time")

plot(plot_DV_vs_time)

p1 <- Mav_data %>% ggplot() +
  geom_line( aes( x = TIME, y = DV, group = as.factor(ID), color = as.factor(DOSE)) ) +
  facet_wrap( ~ DOSE, scales = "free_y")
plot(p1)

p2 <- ggplot(Mav_data, aes(x=TIME, y=DV)) +
  geom_line( aes( x = TIME, y = DV, group = as.factor(ID), color = as.factor(DOSE)) ) +
  facet_wrap( ~ DOSE, scales = "free_y")
plot(p2)

```

```{r}


#Keeping only OCC=1.
OCC_Mav1 <- Mav_data %>% filter(OCC == 1)
OCC_Mav1 <- OCC_Mav1 %>% filter(OCC == 1)
OCC_Mav1 <- na.omit(OCC_Mav1)

DV_Mav1 <- OCC_Mav1 %>% filter(DV > 0)
DV_Mav1 <- DV_Mav1 %>% filter(DV > 0)
DV_Mav1 <- na.omit(DV_Mav1)

df_Y <- OCC_Mav1 %>% filter(TIME > 0) %>% group_by(ID) %>% summarise(Y=sum(DV))
df_time0 <- OCC_Mav1 %>% filter(TIME == 0)
Combo_Mav1 <- left_join(df_Y, df_time0, by = "ID")

Combo_Mav1 <- Combo_Mav1 %>% 
  select(Y,DOSE,AGE,SEX,RACE,WT,HT)

Combo_Mav1 <- Combo_Mav1 %>% mutate(RACE = ifelse(RACE %in% c(7,88), 3, RACE ))

#HT is in meters, WT is in kilograms.
Combo_Mav1$BMI <- Combo_Mav1$WT / ((Combo_Mav1$HT)^2)  

#SEX as a number/factor
Combo_Mav1 <- Combo_Mav1 %>% mutate(
  SEX = ifelse(SEX == 1, "M", "F" ),
  SEX = factor(SEX)
  )

Combo_Mav1 <- Combo_Mav1 %>% mutate(
    RACE = factor(RACE)
  )

print(Combo_Mav1)

#Okay, that looks pretty good.




```

```{r}
#Model Fitting

# fit the linear models with Y as outcome 
# first model has only DOSE as predictor
# second model has all variables as predictors
lin_mod <- linear_reg() %>% set_engine("lm")
linfit1 <- lin_mod %>% fit(Y ~ DOSE, data = Combo_Mav1)
linfit2 <- lin_mod %>% fit(Y ~ ., data = Combo_Mav1)

# Compute the RMSE and R squared for model 1
metrics_1 <- linfit1 %>% 
  predict(Combo_Mav1) %>% 
  bind_cols(Combo_Mav1) %>% 
  metrics(truth = Y, estimate = .pred)

# Compute the RMSE and R squared for model 2
metrics_2 <- linfit2 %>% 
  predict(Combo_Mav1) %>% 
  bind_cols(Combo_Mav1) %>% 
  metrics(truth = Y, estimate = .pred)

# Print the results
print(metrics_1)
print(metrics_2)


```

```{r}
#Logistic Models

# fit the logistic models with SEX as outcome 
# first model has only DOSE as predictor
# second model has all variables as predictors
log_mod <- logistic_reg() %>% set_engine("glm")
logfit1 <- log_mod %>% fit(SEX ~ DOSE, data = Combo_Mav1)
logfit2 <- log_mod %>% fit(SEX ~ ., data = Combo_Mav1)

# Compute the accuracy for model 1
m1_acc <- logfit1 %>% 
  predict(Combo_Mav1) %>% 
  bind_cols(Combo_Mav1) %>% 
  metrics(truth = SEX, estimate = .pred_class) %>% 
  filter(.metric == "accuracy") 


# Compute the accuracy for model 2
m2_acc <- logfit2 %>% 
  predict(Combo_Mav1) %>% 
  bind_cols(Combo_Mav1) %>% 
  metrics(truth = SEX, estimate = .pred_class) %>% 
  filter(.metric %in% c("accuracy"))

# Print the results
print(m1_acc)
print(m2_acc)

```

# I never got this section to work.

#The error I kept getting was this:

#Error in `roc_auc()`: #! Can't subset columns that don't exist. #âœ– Column `.pred_1` doesn't exist. #Backtrace: \# 1. ... %\>% roc_auc(truth = SEX, .pred_1) \# 3. yardstick:::roc_auc.data.frame(., truth = SEX, .pred_1)

#Katie had not used this function before either and neither of us could figure out what the issue is. We even asked ChatGPT and good ol' Chattie said to change ".pred_1" to ".pred = .pred_1". That didn't work either.

# Compute the AUC for model 1

m1_auc \<- logfit1 %\>% predict(Combo_Mav1, type = "prob") %\>% bind_cols(Combo_Mav1) %\>% roc_auc(truth = SEX, .pred_1)

# Compute the AUC for model 2

m2_auc \<- logfit2 %\>% predict(Combo_Mav1, type = "prob") %\>% bind_cols(Combo_Mav1) %\>% roc_auc(truth = SEX, .pred_1)

# Print the results

print(m1_auc) print(m2_auc)

## Unit 10 Material

```{r}
#Part 10 Material.

#Okay, since I have already gotten all of my data loaded and prepped, see the data section above, I don't need to load anything up and clean it.  All those steps are already done since I did the data part all at once for the models exercise and then just copied it here.

#But I will set a seed!

#Once again, part of this code is mine and worked (mostly the data manipulation) and part is from the key from Dr. Handel.

rngseed=1234

#Getting rid of RACE.

Combo_Mav2 <- Combo_Mav1 %>% 
  select(Y,DOSE,AGE,SEX,WT,HT)

print(Combo_Mav2)

#Okay, this water is a bit deep for me.
set.seed(rngseed)
data_split <- initial_split(Combo_Mav2, prop = 3/4)

# Create data frames for the two sets:
train_data <- training(data_split)
test_data  <- testing(data_split)

# record number of observations in each dataset, need that later -- This is Dr. Handel's
Ntrain = nrow(train_data)
Ntest = nrow(test_data)

print(train_data)
print(test_data)

#Okay, that worked.  What now?  Fit models to outcome Y for dose and all remaining variables?  And find the RMSE.  Okay. Here goes.

#My first try, without actually making a model.  In my head, I thought that a linear regression WAS a model.

#First, DOSE.

lmfitC1 <- lm(Y ~ DOSE, train_data)  

# place results from fit into a data frame with the tidy function
lmtableC1 <- broom::tidy(lmfitC1)

#look at fit results
print(lmtableC1)

# Predict the values using the model
predictions <- predict(lmfitC1, train_data)

# Calculate the residuals (differences between observed and predicted values)
residuals1 <- train_data$Y - predictions

# Calculate the RMSE
rmse1 <- sqrt(mean(residuals1^2))

# Print the RMSE
print(rmse1)

#Then All of them!

lmfitC2 <- lm(Y ~ AGE + DOSE + SEX + WT + HT, train_data) 


# place results from fit into a data frame with the tidy function
lmtableC2 <- broom::tidy(lmfitC2)

#look at fit results
print(lmtableC2)

# Predict the values using the model
predictions <- predict(lmfitC2, train_data)

# Calculate the residuals (differences between observed and predicted values)
residuals2 <- train_data$Y - predictions

# Calculate the RMSE
rmse2 <- sqrt(mean(residuals2^2))

# Print the RMSE
print(rmse2)

#This was my attempt at a model:
#Trying it this way... with train data.
linear_reg() %>% set_engine("glm")
model_trial <- linear_reg()
fit_trial1 <- model_trial %>% fit(Y ~ AGE * DOSE * SEX * WT * HT, data = train_data)

tidy(fit_trial1)

predictions <- predict(fit_trial1, train_data)
residuals_mod <- train_data$Y - predictions
rmse_mod <- sqrt(mean(residuals_mod^2))
print(rmse_mod)

#Obviously I did not understand what I was doing.

#This is a general linear model.
mod <- linear_reg() %>% set_engine("lm")

## ---- model1 --------  
wflow1 <- 
	workflow() %>% 
	add_model(mod) %>%    #Here we are using the linear modle defined above.
	add_formula(Y ~ DOSE)
fit1 <- wflow1 %>% fit(data = train_data)


## ---- model2 --------
wflow2 <- wflow1 %>% update_formula(Y ~ .)
fit2 <- wflow2 %>% fit(data = train_data)


## ---- preds --------
pred1 <- fit1 %>% predict(train_data)
pred2 <- fit2 %>% predict(train_data)
# null model, only predicts the mean for everyone
pred0 <- rep(mean(train_data$Y),Ntrain)

## ---- rmse --------
# Compute the RMSE and R squared for model 1
rmse_train_1 <-  bind_cols(train_data, pred1) %>% 
	rmse(truth = Y, estimate = .pred) 

# Compute the RMSE and R squared for model 2
rmse_train_2 <- bind_cols(train_data, pred2) %>% 
	rmse(truth = Y, estimate = .pred) 

# Compute RMSE for a dumb null model
rmse_train_0 <-  rmse_vec(truth = train_data$Y, estimate = pred0) 

# Print the results
metrics = data.frame(model = c("null model","model 1","model 2"), 
										 rmse = c(rmse_train_0, 
										 				 rmse_train_1$.estimate, 
										 				 rmse_train_2$.estimate) )
print(metrics)


```

#I kept getting an error here that said that it couldn't find my data.

#Okay, now we are going to evaluate our model. suppressPackageStartupMessages(library(modeldata)) suppressPackageStartupMessages(library(recipes))

rnseed = 1234 set.seed(rnseed)

data_split \<- initial_split(Combo_Mav2, prop = 0.9)

# Create data frames for the two sets:

train_data2 \<- training(data_split) test_data2 \<- testing(data_split)

print(train_data2) print(test_data2)

data(train_data2) rec_data2 \<- recipe(Y \~ ., data = train_data2)

rec_data2

print(rec_data2)

# Define the linear regression model

model_trial \<- linear_reg() %\>% set_engine("glm") %\>% translate()

# Define the 10-fold cross-validation plan

cv \<- vfold_cv(train_data2, v = 10, repeats =10, strata = NULL)

#This is as far as I got. I couldn't get this to work.

#okay, if I use Combo_mav2 then I get an error in the next line: Must perform recipe. #If I use a recipe then I just get a null set.

# Perform cross-validation

lm_results \<- fit_resamples( model_trial, cv, metrics = metric_set(rmse, rsq) )

# Summarize the results

summary(lm_results)

```{r}
#Obviously this is Dr. Handel's answer.

## ---- cross-validation --------
set.seed(rngseed)
folds <- vfold_cv(train_data, v = 10, repeats = 1)

fit1_cv <- wflow1 %>% fit_resamples(folds)
fit2_cv <- wflow2 %>% fit_resamples(folds)

# pulls out the RMSE from what collect_metrics returns
rmse_cv_1 <- collect_metrics(fit1_cv)$mean[1]
rmse_cv_2 <- collect_metrics(fit2_cv)$mean[1]

# pulls out the SE of the RMSE 
se_cv_1 <- collect_metrics(fit1_cv)$std_err[1]
se_cv_2 <- collect_metrics(fit2_cv)$std_err[1]


# Print the results
metrics_cv = data.frame(model = c("null","model 1","model 2"), 
												rmse = c(rmse_train_0, rmse_cv_1, rmse_cv_2), se = c(0, se_cv_1, se_cv_2) )
print(metrics_cv)

## ---- obs-pred-plot --------
pred0a <- data.frame(predicted = pred0, model = "model 0")
pred1a <- data.frame(predicted = pred1$.pred, model = "model 1")
pred2a <- data.frame(predicted = pred2$.pred, model = "model 2")

plot_data <- bind_rows(pred0a,pred1a,pred2a) %>% 
	mutate(observed = rep(train_data$Y,3)) 

p1 <- plot_data %>% ggplot() +
	geom_point(aes(x = observed, y = predicted, color = model, shape = model)) +
	labs(x = "Observed", y = "Predicted", title = "Predicted vs Observed") +
	geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
	scale_x_continuous(limits=c(0,5000)) +
	scale_y_continuous(limits=c(0,5000)) +
	theme_minimal()
plot(p1)


## ---- residuals-plot --------
plot_data1 <- plot_data |> mutate(residuals = predicted-observed) |> filter(model == "model 2")
p1a <- plot_data1 %>% ggplot() +
	geom_point(aes(x = predicted, y = residuals, color = model, shape = model)) +
	labs(x = "Predicted", y = "Residuals", title = "Residuals vs Predicted") +
	geom_abline(intercept = 0, slope = 0, linetype = "dashed", color = "black") +
	scale_y_continuous(limits=c(-2500,2500)) +
	theme_minimal()
plot(p1a)




## ---- bootstrap --------
Nsamp = 100 #number of samples
set.seed(rngseed)

# create samples
dat_bs <- train_data |> rsample::bootstraps(times = Nsamp)

#set up empty arrays to store predictions for each sample
pred_bs = array(0, dim=c(Nsamp,Ntrain))

#loop over each bootstrap sample, fit model, then predict and record predictions
for (i in 1:Nsamp) {
	dat_sample = rsample::analysis(dat_bs$splits[[i]])
	fit_bs <- wflow2 |> fit(data = dat_sample)
	pred_df <- fit_bs %>% predict(train_data)
	pred_bs[i,] <- pred_df$.pred %>% unlist()
}


#compute median and 89% confidence interval for predictions
preds <- pred_bs |> apply(2, quantile,  c(0.055, 0.5, 0.945)) |>  t()


#make plot showing uncertainty
plot_data2 <- data.frame(
	median = preds[,2],
	lb = preds[,1],
	ub = preds[,3],
	observed = rep(train_data$Y,3),
	mean = pred2a$predicted
) 

p2 <- plot_data2 %>% ggplot() +
	geom_errorbar(aes(x = observed, ymin = lb, ymax = ub), width = 25) +
	geom_point(
		aes(x = observed, y = median, color = "median"),
		shape = 5
	) +
	geom_point(
		aes(x = observed, y = mean, color = "mean"),
		shape = 6
	) +
	labs(x = "Observed", y = "Predicted", title = "Predicted vs Observed") +
	geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
	scale_x_continuous(limits=c(0,5000)) +
	scale_y_continuous(limits=c(0,5000)) +
	scale_color_manual(name = "stat", values = c("orange", "blue")) +
	theme_minimal()
plot(p2)



## ---- final testing --------
predf <- fit2 %>% predict(test_data)
plot_f <- predf %>% mutate(observed = rep(test_data$Y,1)) %>% rename(predicted = .pred)

final_plot_data <-
	dplyr::bind_rows(
		"train" = dplyr::filter(plot_data, model == "model 2"),
		"test" = plot_f,
		.id = "set"
	) |>
	tibble::tibble() |>
	dplyr::select(-model)

p3 <- ggplot(final_plot_data) +
	aes(
		x = observed,
		y = predicted,
		color = set,
		shape = set
	) +
	geom_point() +
	labs(x = "Observed", y = "Predicted", title = "Predicted vs Observed") +
	geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
	scale_x_continuous(limits=c(0,5000)) +
	scale_y_continuous(limits=c(0,5000)) +
	theme_minimal()
plot(p3)




```
